# test 폴더       

test 데이터가 들어있습니다. 

- test-전처리한거.csv    
- test.csv    

​      

# train 폴더

용량 문제로 train 데이터를 아직 올리지 못했습니다.      

train 데이터가 필요한 경우 0904bong@sogang.ac.kr로 연락바랍니다.      

​         

# 데이터수집-전처리, 데이터수집부터 전처리까지.docx           

데이터 수집부터 전처리까지 과정입니다.        

파일 이름의 번호 순으로 읽어보시면 됩니다.

- 1-곡번호가져오기.ipynb
- 2-곡번호to가사.ipynb
- 3-19금-곡번호-가져오기.ipynb
- 4-19금-가사-가져오기.ipynb
- 5-원래데이터에-19금가사-추가해주기.ipynb
- 6-결측치 제거(indi-folk-rock-hiphop-ballad).ipynb
- 7-중복제거,모든장르데이터통합.ipynb
- 8-장르 겹치는 거 묶어주기.ipynb
- 9-훈련, 테스트 데이터 나누기.ipynb
- 10-전처리.ipynb

​      

​      

# Seq2Seq,Attention,Transformer--Review.md      

'Attention Is All You Need' 논문을 읽기 전 Seq2Seq, Attention, Transformer를 복습하면서 간단하게 정리해봤습니다.          

​            

# BERT--review.md          

'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding' 논문을 리뷰해봤습니다.

# Attention-Is-All-You-Need--Review.md     

'Attention Is All You Need' 논문을 번역해봤습니다.        

Seq2Seq,Attention,Transformer--Review.md 에서  Transformer 요약과 병합할 예정입니다.       

​        

​          

# BERT.ipynb, BERT.docx       

Multilingual로 pretrained한 버트 모델으로  train data를 학습 시켜봤습니다.       

BERT.docx 는 모델 학습 과정을 이미지와 함께 설명해봤습니다.        

​       

​        

# HuggingFace Transformers tokenize techinques.md           

Transformers 라이브러리에서 내 토크나이저 종류에 대해 정리해봤습니다. 

​            

​            
